{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from midi_to_dataframe import NoteMapper, MidiReader, MidiWriter\n",
    "import IPython\n",
    "from IPython.display import Image, IFrame\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import music21\n",
    "import pickle\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Mappings File\n",
    "\n",
    "A **NoteMapper** object encapsulates how MIDI note information is converted to text to be displayed within a DataFrame. This object is initialized from a JSON file, containing three objects:\n",
    "\n",
    "* **midi-to-text**: JSON mapping of MIDI program numbers to their textual representation. Used when converting MIDI files to DataFrames.\n",
    "    * For example: *{\"0\": \"piano\"}*\n",
    "* **text-to-midi**: JSON mapping of textual representations of MIDI instruments to MIDI program numbers. Used when writing DataFrames to MIDI.\n",
    "    * For example: *{\"piano\": 0}*\n",
    "* **durations**: JSON mapping of textual representations of MIDI instruments to predefined quantization values (in quarter notes). Used when converted MIDI files to DataFrames.\n",
    "    * For example: *{\"piano\": [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3, 4, 6, 8, 12, 16]}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_mapping_config_path = \"./config/map-to-group.json\"\n",
    "note_mapper = NoteMapper(note_mapping_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert a MIDI file to a DataFrame\n",
    "\n",
    "The **MidiReader** object is used to read a MIDI file from disk and convert it to a **DataFrame**. A **NoteMapper** object is passed to the MidiReader upon initialization to handle the MIDI to text conversion of note durations and program names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = MidiReader(note_mapper)\n",
    "\n",
    "# getting midi files\n",
    "filepath = \"./datasets/dataset_pop/\"\n",
    "MidiDataDF = pd.DataFrame()\n",
    "count = 0\n",
    "\n",
    "for filename in os.listdir(filepath):\n",
    "    if filename.endswith(\".midi\"):\n",
    "        \n",
    "        # create file path\n",
    "        count += 1\n",
    "        #print(count, filename, end = \" \")\n",
    "        fullFilePath = filepath+filename\n",
    "\n",
    "        # read file as dataframe\n",
    "        tempDF = reader.convert_to_dataframe(fullFilePath)\n",
    "        #print(tempDF.shape[0])\n",
    "        MidiDataDF = MidiDataDF.append(tempDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MidiDataDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIDI DataFrame\n",
    "\n",
    "The created DataFrame object contains the sequence of musical notes found in the input MIDI file, quantized by 16th notes and the following rows:\n",
    "\n",
    "* **timestamp**: the MIDI timestamp (tick)\n",
    "* **bpm**: the beats per minute at the timestamp\n",
    "* **time_signature**: the time signature at the timestamp\n",
    "* **measure**: the measure number at the timestamp\n",
    "* **beat**: the downbeat within the current measure at the timestamp, in quarter notes\n",
    "* **notes**: a textual representation of the notes played at the current timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NotesDataDF = MidiDataDF[[\"notes\"]]\n",
    "#NotesDataDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = [\"rest\"] # add rest by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = ['bass', 'synthlead', 'synthfx', 'reed',\n",
    "               'percussive', 'organ', 'guitar', 'pipe',\n",
    "               'soundfx', 'chromatic', 'ethnic', 'piano',\n",
    "               'brass', 'synthpad', 'ensemble', 'strings']\n",
    "\n",
    "percussionInstruments = ['acousticbassdrum', 'bassdrum', 'rimshot', 'acousticsnare',\n",
    "                         'clap', 'snare', 'lowfloortom', 'closedhat', 'highfloortom',\n",
    "                         'pedalhat', 'lowtom', 'openhat', 'lowmidtom', 'highmidtom',\n",
    "                         'crashcymbal', 'hightom', 'ridecymbal', 'chinesecymbal',\n",
    "                         'ridebell', 'tambourine', 'splashcymbal', 'cowbell', 'vibraslap',\n",
    "                         'highbongo', 'lowbongo', 'mutehighconga', 'openhighconga', 'lowconga',\n",
    "                         'hightimbale', 'lowtimbale', 'highagogo', 'lowagogo', 'cabasa',\n",
    "                         'maracas', 'shortwhistle', 'longwhistle', 'shortguiro', 'longguiro',\n",
    "                         'claves', 'highwoodblock', 'lowwoodblock', 'mutecuica', 'opencuica',\n",
    "                         'mutetriangle', 'opentriangle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'g7', 'd9', 'c1', 'a1', 'g8', 'c3', 'd7', 'c#2', 'a8', 'b2', 'f6', 'b7', 'f#7', 'g3', 'd2', 'f8', 'g4', 'c#8', 'e5', 'g#7', 'd#4', 'g#4', 'a#8', 'c0', 'a#6', 'a#5', 'c#4', 'b3', 'b4', 'c6', 'f#8', 'e9', 'g#2', 'd6', 'g0', 'b5', 'f#0', 'e1', 'd#5', 'c#3', 'g6', 'f5', 'd#7', 'c8', 'g5', 'd4', 'c#1', 'a6', 'e2', 'd8', 'g#8', 'g#1', 'g9', 'f0', 'f7', 'd5', 'a#0', 'e6', 'f4', 'd#8', 'f#2', 'b8', 'e4', 'f2', 'b1', 'c4', 'g2', 'g#6', 'g1', 'e7', 'c9', 'a2', 'f#1', 'c7', 'g#5', 'a4', 'd1', 'g#3', 'f9', 'e3', 'e0', 'c#0', 'c5', 'b0', 'd3', 'a#2', 'c#5', 'a#1', 'a5', 'a3', 'd#2', 'd#9', 'c#7', 'f#3', 'f#6', 'c#6', 'a#7', 'a7', 'e8', 'f1', 'd#3', 'b6', 'c2', 'f#5', 'c#9', 'd#6', 'd#1', 'f#4', 'd#0', 'a#4', 'a#3', 'f3', 'd0'}\n"
     ]
    }
   ],
   "source": [
    "notesTemp = list(NotesDataDF[\"notes\"])\n",
    "chordsList = []\n",
    "\n",
    "for i in notesTemp:\n",
    "    if i != \"rest\":\n",
    "        indexSplit = i.split(\",\")\n",
    "        for j in indexSplit:\n",
    "            chord = j.split(\"_\")\n",
    "            if chord[0] != \"percussion\":\n",
    "                chordsList.append(chord[1])\n",
    "        \n",
    "chordsList = set(chordsList)\n",
    "print(chordsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'piano': [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0, 6.0, 8.0, 12.0, 16.0], 'chromatic': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'organ': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'guitar': [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0, 6.0, 8.0, 12.0, 16.0, 24.0, 28.0, 32.0], 'bass': [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0, 6.0, 8.0, 12.0, 16.0], 'strings': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'ensemble': [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0, 6.0, 8.0, 12.0, 16.0], 'brass': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'reed': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'pipe': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'synthlead': [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0, 6.0, 8.0, 12.0, 16.0], 'synthpad': [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0, 6.0, 8.0, 12.0, 16.0], 'synthfx': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'ethnic': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0], 'percussive': [0.25], 'soundfx': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0], 'percussion': [0.25]}\n"
     ]
    }
   ],
   "source": [
    "f = open(note_mapping_config_path)\n",
    "jsonData = json.load(f)\n",
    "f.close()\n",
    "\n",
    "print(jsonData[\"durations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21629\n"
     ]
    }
   ],
   "source": [
    "for i in instruments:\n",
    "    for c in chordsList:\n",
    "        for d in jsonData[\"durations\"][i]:\n",
    "            word = str(i) + \"_\" + str(c) + \"_\" + str(d)\n",
    "            vocabulary.append(word)\n",
    "            \n",
    "for p in percussionInstruments:\n",
    "    word = \"percussion_\" + str(p) + \"_0.25\"\n",
    "    vocabulary.append(word)\n",
    "            \n",
    "print(len(vocabulary))\n",
    "#print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dictionary to Map Word onto Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabMappings = dict(zip(vocabulary, range(0, len(vocabulary))))\n",
    "#print(vocabMappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Data To Integers (Forward Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183421\n"
     ]
    }
   ],
   "source": [
    "notesTemp = list(NotesDataDF[\"notes\"])\n",
    "mappedNotes = []\n",
    "\n",
    "for i in notesTemp:\n",
    "    indexSplit = i.split(\",\")\n",
    "    for j in indexSplit:\n",
    "        if len(indexSplit) > 1:\n",
    "            mapping = int(vocabMappings[j]) * (-1)\n",
    "        else:\n",
    "            mapping = int(vocabMappings[j])\n",
    "        mappedNotes.append(mapping)\n",
    "\n",
    "print(len(mappedNotes))\n",
    "#mappedNotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16591671\n",
      "10 1 4 5 8 6 11 10 1 5 2 4 6 11 10 1 4 3 3 1 11 0 11 0 11 0 11 10 1 4 3 3 1 11 10 1 5 2 4 6 11 10 1 \n"
     ]
    }
   ],
   "source": [
    "vocabularyChars = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\"] # 10 is minus (-) and 11 is comma (,)\n",
    "mappedNotesChars = []\n",
    "\n",
    "for note in mappedNotes:\n",
    "    temp = str(note)\n",
    "    tempArr = [*temp]\n",
    "    if tempArr[0] == \"-\":\n",
    "        tempArr[0] = \"10\"\n",
    "    tempArr.append(\"11\")\n",
    "    mappedNotesChars.extend(tempArr)\n",
    "    \n",
    "# Convert the list to a string with each element separated by a space\n",
    "mappedNotesString = \" \".join(mappedNotesChars)\n",
    "\n",
    "print(len(mappedNotesString))\n",
    "print(mappedNotesString[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN + LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data For Input Into Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Data:\n",
    "    features = []\n",
    "    targets = []\n",
    "    featureLength = 1000\n",
    "    def __init__(self, features, targets, featureLength):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.featureLength = featureLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To NP:\n"
     ]
    }
   ],
   "source": [
    "print(\"To NP:\")\n",
    "mappedNotesChars = np.array(mappedNotesChars, dtype=float)\n",
    "\n",
    "d = Data([],[],1000)\n",
    "\n",
    "for i in range(len(mappedNotesChars)-d.featureLength):\n",
    "    #print(\"Index:\", i)\n",
    "    tempF = mappedNotesChars[i:i+d.featureLength]\n",
    "    d.features.append(tempF)\n",
    "    tempT = mappedNotesChars[i+d.featureLength]\n",
    "    d.targets.append(tempT)\n",
    "    \n",
    "n_patterns = len(d.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7201917\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(d.targets))\n",
    "print(len(d.features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(d.features[0][0])\n",
    "print(d.targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(d, open('pop_data.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 53.7 GiB for an array with shape (7206088, 1000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_patterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatureLength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m, method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 53.7 GiB for an array with shape (7206088, 1000) and data type float64"
     ]
    }
   ],
   "source": [
    "features = np.reshape(features, (n_patterns, featureLength, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "targets = np.array(targets)\n",
    "targets = to_categorical(targets, len(vocabularyChars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features[0], targets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(features.shape[1],features.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(vocabulary), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(features, targets, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Integers to Data (Backward Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mappedNotes[0:2000]\n",
    "concatStr = \"\"\n",
    "reverseMapping = []\n",
    "\n",
    "for i in output:\n",
    "    if i < 0:\n",
    "        i = i * (-1)\n",
    "        result = [new_k for new_k in vocabMappings.items() if new_k[1] == i][0][0]\n",
    "        concatStr = concatStr + \",\" + result\n",
    "    else:\n",
    "        if concatStr != \"\":\n",
    "            reverseMapping.append(concatStr.lstrip(\",\"))\n",
    "            concatStr = \"\"\n",
    "        result = [new_k for new_k in vocabMappings.items() if new_k[1] == i][0][0]\n",
    "        reverseMapping.append(result)\n",
    "        \n",
    "reverseMapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert a DataFrame to a MIDI File\n",
    "\n",
    "The **MidiWriter** object handles writing properly-formatted **DataFrames** as playable MIDI files. A **NoteMapper** object is passed to the MidiWriter upon initialization to handle the text to MIDI conversion of note durations and program names. The path and filename of the output MIDI file is specified in the *convert_to_midi* call of the MidiWriter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDF = pd.DataFrame(reverseMapping, columns =['notes'])\n",
    "outputDF[\"bpm\"] = 125\n",
    "\n",
    "cols = outputDF.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "outputDF = outputDF[cols]\n",
    "\n",
    "outputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop the first 15 rows of the dataframe, which represented 1 measure of silence\n",
    "\n",
    "# Write the modified DataFrame to disk as a playable MIDI file\n",
    "writer = MidiWriter(note_mapper)\n",
    "writer.convert_to_midi(outputDF, \"./output.midi\")\n",
    "\n",
    "parsed = music21.converter.parse(\"./output.midi\")\n",
    "parsed.write('musicxml.png', fp='./sheets/Score')\n",
    "pdfPath = parsed.write('lily.pdf', fp='./sheets/Score')\n",
    "\n",
    "filepath = \"./sheets/\"\n",
    "for filename in os.listdir(filepath):\n",
    "    if filename.endswith(\".png\"):\n",
    "        im = Image.open(filepath+filename)\n",
    "        bg = Image.new(\"RGB\", im.size, (255,255,255))\n",
    "        bg.paste(im,im)\n",
    "        os.remove(filepath+filename)\n",
    "        filename = filename.replace(\".png\",\".jpg\")\n",
    "        bg.save(filepath+filename)\n",
    "\n",
    "os.remove(filepath + \"Score\")\n",
    "os.remove(filepath + \"Score.musicxml\")\n",
    "\n",
    "IFrame(str(pdfPath), width=900, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
