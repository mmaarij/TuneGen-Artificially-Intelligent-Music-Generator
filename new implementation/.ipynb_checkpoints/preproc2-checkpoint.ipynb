{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "35c43f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from midi_to_dataframe import NoteMapper, MidiReader, MidiWriter\n",
    "import IPython\n",
    "from IPython.display import Image, IFrame\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import music21\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ec629d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_mapping_config_path = \"./config/map-to-group.json\"\n",
    "note_mapper = NoteMapper(note_mapping_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d0c0a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = MidiReader(note_mapper)\n",
    "\n",
    "# getting midi files\n",
    "filepath = \"./datasets/dataset_pop/\"\n",
    "MidiDataDF = pd.DataFrame()\n",
    "count = 0\n",
    "\n",
    "for filename in os.listdir(filepath):\n",
    "    if filename.endswith(\".midi\"):\n",
    "        \n",
    "        # create file path\n",
    "        count += 1\n",
    "        #print(count, filename, end = \" \")\n",
    "        fullFilePath = filepath+filename\n",
    "\n",
    "        # read file as dataframe\n",
    "        tempDF = reader.convert_to_dataframe(fullFilePath)\n",
    "        #print(tempDF.shape[0])\n",
    "        MidiDataDF = MidiDataDF.append(tempDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba31b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(MidiDataDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "94e33709",
   "metadata": {},
   "outputs": [],
   "source": [
    "NotesDataDF = MidiDataDF[[\"notes\"]]\n",
    "#NotesDataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "50214d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=',')\n",
    "tokenizer.fit_on_texts(NotesDataDF['notes'])\n",
    "sequences = tokenizer.texts_to_sequences(NotesDataDF['notes'])\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "67f07e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum length of the sequences\n",
    "max_sequence_len = max(len(s) for s in sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cde85fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(sequences, batch_size, max_sequence_len, num_classes):\n",
    "    while True:\n",
    "        X = np.zeros((batch_size, max_sequence_len), dtype=np.int32)\n",
    "        y = np.zeros((batch_size, max_sequence_len, num_classes), dtype=np.int32)\n",
    "        for i in range(batch_size):\n",
    "            idx = np.random.randint(len(sequences))\n",
    "            seq = sequences[idx]\n",
    "            X[i, :len(seq)] = seq\n",
    "            y[i, :-1] = to_categorical(X[i, 1:], num_classes=num_classes)\n",
    "            y[i, -1] = to_categorical(X[i, 0], num_classes=num_classes)[0]\n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9452c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "train_gen = generate_sequences(sequences, batch_size, max_sequence_len, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9f487f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 348, 128)          640000    \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 348, 128)          131584    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 348, 128)          0         \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5000)              645000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,548,168\n",
      "Trainable params: 1,548,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 128, input_length=max_sequence_len))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(max_words, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "50147a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0db6c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/remove_squeezable_dimensions/Squeeze' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/maarij/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/maarij/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 530, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/home/maarij/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/maarij/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/maarij/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1301/2887135149.py\", line 5, in <module>\n      model.fit(train_gen, steps_per_epoch=len(sequences)//batch_size, epochs=50, callbacks=callbacks_list)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n      return self.compiled_loss(\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/losses.py\", line 277, in call\n      y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/utils/losses_utils.py\", line 200, in squeeze_or_expand_dimensions\n      y_true, y_pred = remove_squeezable_dimensions(y_true, y_pred)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/utils/losses_utils.py\", line 139, in remove_squeezable_dimensions\n      labels = tf.squeeze(labels, [-1])\nNode: 'sparse_categorical_crossentropy/remove_squeezable_dimensions/Squeeze'\nCan not squeeze dim[2], expected a dimension of 1, got 5000\n\t [[{{node sparse_categorical_crossentropy/remove_squeezable_dimensions/Squeeze}}]] [Op:__inference_train_function_46720]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m callbacks_list \u001b[38;5;241m=\u001b[39m [checkpoint]\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/remove_squeezable_dimensions/Squeeze' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/maarij/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/maarij/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/maarij/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 530, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/home/maarij/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/maarij/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/maarij/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1301/2887135149.py\", line 5, in <module>\n      model.fit(train_gen, steps_per_epoch=len(sequences)//batch_size, epochs=50, callbacks=callbacks_list)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n      return self.compiled_loss(\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/losses.py\", line 277, in call\n      y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/utils/losses_utils.py\", line 200, in squeeze_or_expand_dimensions\n      y_true, y_pred = remove_squeezable_dimensions(y_true, y_pred)\n    File \"/home/maarij/.local/lib/python3.10/site-packages/keras/utils/losses_utils.py\", line 139, in remove_squeezable_dimensions\n      labels = tf.squeeze(labels, [-1])\nNode: 'sparse_categorical_crossentropy/remove_squeezable_dimensions/Squeeze'\nCan not squeeze dim[2], expected a dimension of 1, got 5000\n\t [[{{node sparse_categorical_crossentropy/remove_squeezable_dimensions/Squeeze}}]] [Op:__inference_train_function_46720]"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "filepath = \"./checkpoints/best_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(train_gen, steps_per_epoch=len(sequences)//batch_size, epochs=50, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a2c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
