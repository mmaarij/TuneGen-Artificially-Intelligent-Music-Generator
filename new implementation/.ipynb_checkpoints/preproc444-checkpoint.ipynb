{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/maarij/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from midi_to_dataframe import NoteMapper, MidiReader, MidiWriter\n",
    "import IPython\n",
    "from IPython.display import Image, IFrame\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import music21\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Mappings File\n",
    "\n",
    "A **NoteMapper** object encapsulates how MIDI note information is converted to text to be displayed within a DataFrame. This object is initialized from a JSON file, containing three objects:\n",
    "\n",
    "* **midi-to-text**: JSON mapping of MIDI program numbers to their textual representation. Used when converting MIDI files to DataFrames.\n",
    "    * For example: *{\"0\": \"piano\"}*\n",
    "* **text-to-midi**: JSON mapping of textual representations of MIDI instruments to MIDI program numbers. Used when writing DataFrames to MIDI.\n",
    "    * For example: *{\"piano\": 0}*\n",
    "* **durations**: JSON mapping of textual representations of MIDI instruments to predefined quantization values (in quarter notes). Used when converted MIDI files to DataFrames.\n",
    "    * For example: *{\"piano\": [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3, 4, 6, 8, 12, 16]}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_mapping_config_path = \"./config/map-to-group.json\"\n",
    "note_mapper = NoteMapper(note_mapping_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert a MIDI file to a DataFrame\n",
    "\n",
    "The **MidiReader** object is used to read a MIDI file from disk and convert it to a **DataFrame**. A **NoteMapper** object is passed to the MidiReader upon initialization to handle the MIDI to text conversion of note durations and program names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = MidiReader(note_mapper)\n",
    "\n",
    "# getting midi files\n",
    "filepath = \"./datasets/dataset_pop/\"\n",
    "MidiDataDF = pd.DataFrame()\n",
    "count = 0\n",
    "\n",
    "for filename in os.listdir(filepath):\n",
    "    if filename.endswith(\".midi\"):\n",
    "        \n",
    "        # create file path\n",
    "        count += 1\n",
    "        #print(count, filename, end = \" \")\n",
    "        fullFilePath = filepath+filename\n",
    "\n",
    "        # read file as dataframe\n",
    "        tempDF = reader.convert_to_dataframe(fullFilePath)\n",
    "        #print(tempDF.shape[0])\n",
    "        MidiDataDF = MidiDataDF.append(tempDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MidiDataDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIDI DataFrame\n",
    "\n",
    "The created DataFrame object contains the sequence of musical notes found in the input MIDI file, quantized by 16th notes and the following rows:\n",
    "\n",
    "* **timestamp**: the MIDI timestamp (tick)\n",
    "* **bpm**: the beats per minute at the timestamp\n",
    "* **time_signature**: the time signature at the timestamp\n",
    "* **measure**: the measure number at the timestamp\n",
    "* **beat**: the downbeat within the current measure at the timestamp, in quarter notes\n",
    "* **notes**: a textual representation of the notes played at the current timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NotesDataDF = MidiDataDF[[\"notes\"]]\n",
    "#NotesDataDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = [\"rest\"] # add rest by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = ['bass', 'synthlead', 'synthfx', 'reed',\n",
    "               'percussive', 'organ', 'guitar', 'pipe',\n",
    "               'soundfx', 'chromatic', 'ethnic', 'piano',\n",
    "               'brass', 'synthpad', 'ensemble', 'strings']\n",
    "\n",
    "percussionInstruments = ['acousticbassdrum', 'bassdrum', 'rimshot', 'acousticsnare',\n",
    "                         'clap', 'snare', 'lowfloortom', 'closedhat', 'highfloortom',\n",
    "                         'pedalhat', 'lowtom', 'openhat', 'lowmidtom', 'highmidtom',\n",
    "                         'crashcymbal', 'hightom', 'ridecymbal', 'chinesecymbal',\n",
    "                         'ridebell', 'tambourine', 'splashcymbal', 'cowbell', 'vibraslap',\n",
    "                         'highbongo', 'lowbongo', 'mutehighconga', 'openhighconga', 'lowconga',\n",
    "                         'hightimbale', 'lowtimbale', 'highagogo', 'lowagogo', 'cabasa',\n",
    "                         'maracas', 'shortwhistle', 'longwhistle', 'shortguiro', 'longguiro',\n",
    "                         'claves', 'highwoodblock', 'lowwoodblock', 'mutecuica', 'opencuica',\n",
    "                         'mutetriangle', 'opentriangle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f5', 'e8', 'f#2', 'f9', 'f3', 'a#4', 'g2', 'f#3', 'd8', 'e4', 'g#5', 'c4', 'c3', 'f8', 'g#6', 'd3', 'e5', 'b1', 'f#4', 'c5', 'f1', 'c9', 'f7', 'c#5', 'b6', 'd7', 'c0', 'c#8', 'a4', 'e7', 'a#2', 'a2', 'b5', 'b4', 'd#0', 'c2', 'g#8', 'a3', 'f4', 'g9', 'c7', 'g#1', 'g#4', 'f#6', 'a8', 'd#1', 'a#3', 'c#6', 'e1', 'f#7', 'f#1', 'd6', 'd4', 'e3', 'f2', 'e2', 'd#5', 'd9', 'c#1', 'g5', 'g1', 'g0', 'b8', 'c#4', 'd#6', 'b3', 'a#1', 'a1', 'd#2', 'd#7', 'a5', 'g#7', 'g3', 'e6', 'f#8', 'g#2', 'f6', 'c1', 'b0', 'g8', 'd5', 'c8', 'd#3', 'g6', 'a6', 'd#4', 'a#6', 'd1', 'd2', 'b7', 'a#7', 'c#7', 'f#5', 'a7', 'd#8', 'g4', 'c#9', 'd#9', 'c#3', 'a#5', 'e9', 'g7', 'g#3', 'b2', 'c#2', 'c6'}\n"
     ]
    }
   ],
   "source": [
    "notesTemp = list(NotesDataDF[\"notes\"])\n",
    "chordsList = []\n",
    "\n",
    "for i in notesTemp:\n",
    "    if i != \"rest\":\n",
    "        indexSplit = i.split(\",\")\n",
    "        for j in indexSplit:\n",
    "            chord = j.split(\"_\")\n",
    "            if chord[0] != \"percussion\":\n",
    "                chordsList.append(chord[1])\n",
    "        \n",
    "chordsList = set(chordsList)\n",
    "print(chordsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'piano': [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0, 6.0, 8.0, 12.0, 16.0], 'chromatic': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'organ': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'guitar': [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0, 6.0, 8.0, 12.0, 16.0, 24.0, 28.0, 32.0], 'bass': [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0, 6.0, 8.0, 12.0, 16.0], 'strings': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'ensemble': [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0, 6.0, 8.0, 12.0, 16.0], 'brass': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'reed': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'pipe': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'synthlead': [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0, 6.0, 8.0, 12.0, 16.0], 'synthpad': [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0, 6.0, 8.0, 12.0, 16.0], 'synthfx': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0, 16.0], 'ethnic': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0], 'percussive': [0.25], 'soundfx': [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 8.0, 12.0], 'percussion': [0.25]}\n"
     ]
    }
   ],
   "source": [
    "f = open(note_mapping_config_path)\n",
    "jsonData = json.load(f)\n",
    "f.close()\n",
    "\n",
    "print(jsonData[\"durations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20292\n"
     ]
    }
   ],
   "source": [
    "for i in instruments:\n",
    "    for c in chordsList:\n",
    "        for d in jsonData[\"durations\"][i]:\n",
    "            word = str(i) + \"_\" + str(c) + \"_\" + str(d)\n",
    "            vocabulary.append(word)\n",
    "            \n",
    "for p in percussionInstruments:\n",
    "    word = \"percussion_\" + str(p) + \"_0.25\"\n",
    "    vocabulary.append(word)\n",
    "            \n",
    "print(len(vocabulary))\n",
    "#print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dictionary to Map Word onto Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabMappings = dict(zip(vocabulary, range(0, len(vocabulary))))\n",
    "#print(vocabMappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Data To Integers (Forward Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874450\n"
     ]
    }
   ],
   "source": [
    "notesTemp = list(NotesDataDF[\"notes\"])\n",
    "mappedNotes = []\n",
    "\n",
    "for i in notesTemp:\n",
    "    indexSplit = i.split(\",\")\n",
    "    for j in indexSplit:\n",
    "        if len(indexSplit) > 1:\n",
    "            mapping = int(vocabMappings[j]) * (-1)\n",
    "        else:\n",
    "            mapping = int(vocabMappings[j])\n",
    "        mappedNotes.append(mapping)\n",
    "\n",
    "print(len(mappedNotes))\n",
    "#mappedNotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12152858\n",
      "10 1 3 9 8 8 11 10 1 3 4 3 3 11 10 1 3 7 7 8 11 0 11 0 11 0 11 10 1 3 7 7 8 11 10 1 3 4 3 3 11 10 1 \n"
     ]
    }
   ],
   "source": [
    "vocabularyChars = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\"] # 10 is minus (-) and 11 is comma (,)\n",
    "mappedNotesChars = []\n",
    "\n",
    "for note in mappedNotes:\n",
    "    temp = str(note)\n",
    "    tempArr = [*temp]\n",
    "    if tempArr[0] == \"-\":\n",
    "        tempArr[0] = \"10\"\n",
    "    tempArr.append(\"11\")\n",
    "    mappedNotesChars.extend(tempArr)\n",
    "    \n",
    "# Convert the list to a string with each element separated by a space\n",
    "mappedNotesString = \" \".join(mappedNotesChars)\n",
    "\n",
    "print(len(mappedNotesString))\n",
    "print(mappedNotesString[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tokens is 5278049\n",
      "The number of unique tokens are 12\n"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize(mappedNotesString)\n",
    "print(\"The number of tokens is\", len(words)) \n",
    "\n",
    "unique_tokens = set(words)\n",
    "print(\"The number of unique tokens are\", len(unique_tokens)) \n",
    "#prints the number of unique tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 12  #chosen based on statistics of the model\n",
    "oov_tok = '<OOV>'\n",
    "embedding_dim = 100\n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "\n",
    "# tokenizes sentences\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts([mappedNotesString])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "\n",
    "tokens = tokenizer.texts_to_sequences([mappedNotesString])[0]\n",
    "\n",
    "# Pickle the tokenizer object and save it to a file\n",
    "with open(\"./tokenizer.pkl\", 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training data size is - 4900454\n"
     ]
    }
   ],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "seq_length = 50\n",
    "\n",
    "for i in range(0, len(tokens) - seq_length-1 , 1):\n",
    "  seq_in = tokens[i:i + seq_length]\n",
    "  seq_out = tokens[i + seq_length]\n",
    "\n",
    "  if seq_out==1: #Skip samples where target word is OOV\n",
    "    continue\n",
    "    \n",
    "  dataX.append(seq_in)\n",
    "  dataY.append(seq_out)\n",
    " \n",
    "N = len(dataX)\n",
    "print (\"Total training data size is -\", N)\n",
    "\n",
    "X = np.array(dataX)\n",
    "\n",
    "# one hot encodes the output variable\n",
    "y = np.array(dataY)\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define checkpoint path and filename\n",
    "checkpoint_path = \"./model_checkpoint.h5\"\n",
    "\n",
    "# Create a ModelCheckpoint callback that saves the model weights only when validation accuracy improves\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 100)           1200      \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              84480     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87,228\n",
      "Trainable params: 87,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=seq_length),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(32)),\n",
    "    keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with checkpoint\n",
    "num_epochs = 10\n",
    "history = model.fit(X, y, epochs=num_epochs, batch_size=128, verbose=1, validation_split=0.2, callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
